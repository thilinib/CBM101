{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-commentate"
    ]
   },
   "source": [
    "# Open datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquiring Data from open repositories\n",
    "\n",
    "A crucial step in the work of a computational biologist is not only to analyse data, but acquiring datasets to analyse as well as toy datasets to test out computational methods and algorithms. The internet is full of such open datasets. Sometimes you have to sign up and make a user to get authentication, especially for medical data. This can sometimes be time consuming, so here we will deal with easy access resources, mostly of modest size. Multiple python libraries provide somekind of a `dataset` module which makes the effort to fetch online data extremely seamless, with little requirement for preprocessing.\n",
    "\n",
    "\n",
    "### Goal of the notebook\n",
    "\n",
    "Here you will get familiar with some ways to fetch datasets from online. We do some data exploration on the data to see how its shaped by using some basic plots. In previous notebook you learned how to use seaborn and we will use it here too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching online data using modules\n",
    "\n",
    "We start with **scikit-learn's** dataset module. Scikit-learn is a machine learning library that we will use in the Part 3 of this course. Visit [here](https://scikit-learn.org/stable/modules/classes.html?highlight=datasets#module-sklearn.datasets) for an overview of the datasets it provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember in the last notebook we loaded the iris dataset directly from URI using `pd.read_csv()`. We could've also used seaborn's load_dataset module: `sns.load_dataset(\"iris\")`. Here we load the iris dataset from scikit-learn's datasets module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data as object\n",
    "data = load_iris()\n",
    "\n",
    "# You can also set parameter 'return_X_y' True which returns X (data) and y (class) separately:\n",
    "# X, y = load_iris(return_X,y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is a dictionary that has all kind of information\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access different attributes same way you access columns in DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.DESCR)\n",
    "\n",
    "# or\n",
    "# data['DESCR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate the data and create a Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "style-student"
    ]
   },
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <h4> Exercise 1.</h4>  DataFrame is still missing the classes. Make a new column <b>species</b> that has the values of <b>'target'</b>. How do you get the target_names instead of just numbers?\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe is great function to get better view of your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like in the previous notebook you can visualize your data using seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='species', y='sepal length (cm)', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if features correlate with each other you can use `corr()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import local data\n",
    "\n",
    "If you have downloaded data to your computer (in csv format) its easy to access it using e.g. pandas `read_csv` function. Here we have Covid impact on airport traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/covid_impact_on_airport_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you might want to get rid of a few columns we don't need. Let's keep the date, city and PercentOfBaseline which represents the proportion of trips on this date as compared to Avg number of trips on the same day of week in baseline period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# keep only these columns\n",
    "df = df[['Date', 'PercentOfBaseline', 'City']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look into Sydney airport traffic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney = df.loc[df.City=='Sydney'] # subset of only sydney traffic\n",
    "sydney.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney.plot(x='Date', y='PercentOfBaseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "    <h4> Exercise 2.</h4>  Is the plot making sense? What should've been done before plotting?\n",
    "    </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/ex2_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try plotting again\n",
    "sydney.plot(x='Date', y='PercentOfBaseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import your own data\n",
    "\n",
    "Now choose one of the following datasets from Kaggle, download and move it in the data-folder and then do some data exploration. Use examples from previous notebook to make plots.\n",
    "\n",
    "[Heart disease dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)\n",
    "\n",
    "[Breast cancer dataset](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data)\n",
    "\n",
    "[Diabetes dataset](https://www.kaggle.com/datasets/mathchi/diabetes-data-set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do the rows and columns represent here?**\n",
    "\n",
    "**How many samples does the data have? What about features?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose a few features and plot histograms of them. What do they tell you? Describe the plots.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three listed datasets have something called a target variable. It's the feature of the dataset you want to gain better understanding and other features might explain. Usually its some kind of class. For example in iris dataset the target would be the species and explaining variables are the length and the width of the sepals and petals.\n",
    "\n",
    "**What is the target variable in your data? What are the different classes (e.g. if the values are 0s and 1s, what do they mean?)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate correlation between all numeric features using DataFrame function `corr()`. Then use it to make a heatmap.**\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "    <b>Hint!</b> \n",
    "    \n",
    "You can change categorical (non-numeric) features to dummy variables (1/0 i.e. True/False) using \n",
    "    `pd.get_dummies()`\n",
    "    method. E.g. If you have DataFrame <b>df</b> that has column <b>Gender</b> that has M and F values, you can run get_dummies(df, column=['Gender']) and you get two new columns: Gender_F and Gender_M that both consist of boolean values 1 and 0.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose features that correlate (positively or negatively) with your target and make a pairplot using your target as hue. Can you make any interesting observations?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now make at least three other plots of your choice to see what the data is like. You can also calculate statistics and use the information from the heatmap to get ideas what could be interesting to plot. Feel free to experiment and write down any observations you can make from the plots.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Useful resources and links\n",
    "\n",
    "Kaggle is a great place for datasets but there is a lot of other good open sources as well. Here is a list of useful links for public datasets perfect for data-analysis and machine learning:\n",
    "\n",
    "\n",
    "### Links\n",
    "- [OpenML](https://www.openml.org/search?type=data)\n",
    "   - large variety of datasets for machine learning\n",
    "- [Nilearn datasets](https://nilearn.github.io/modules/reference.html#module-nilearn.datasets)\n",
    "   - provides a collection of neuroimaging datasets\n",
    "- [Sklearn datasets](https://scikit-learn.org/stable/modules/classes.html?highlight=datasets#module-sklearn.datasets)\n",
    "- [Kaggle](https://www.kaggle.com/datasets)\n",
    "   - Competition website including wide variety of public datasets and notebooks of users\n",
    "- [MEDMNIST](https://medmnist.com/)\n",
    "   - Biomedical Images for classification\n",
    "\n",
    "\n",
    "- [**Awesomedata**](https://github.com/awesomedata/awesome-public-datasets)\n",
    "\n",
    " - We strongly recommend to check out the Awesomedata lists of public datasets, covering topics such as [biology/medicine](https://github.com/awesomedata/awesome-public-datasets#biology) and [neuroscience](https://github.com/awesomedata/awesome-public-datasets#neuroscience)\n",
    "\n",
    "- [Papers with code](https://paperswithcode.com)\n",
    "   - free and open resource with Machine Learning papers, code, datasets, methods and evaluation tables\n",
    "\n",
    "- [SNAP](https://snap.stanford.edu/data/)\n",
    "  - Stanford Large Network Dataset Collection  \n",
    "- [Open Graph Benchmark (OGB)](https://github.com/snap-stanford/ogb)\n",
    "  - Network datasets\n",
    "- [Open Neuro](https://openneuro.org/)\n",
    "   - platform for validating and sharing neuroimaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
