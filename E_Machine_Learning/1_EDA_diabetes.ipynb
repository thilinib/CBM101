{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9NOKi4KQEsN"
   },
   "source": [
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "In this notebook you will get practical experience with common data exploration steps. Here we will use a well-known dataset often used for machine learning and statistical analysis projects based on the \"**Pima Indians Diabetes Database**\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWS3FFAmvPVX"
   },
   "source": [
    "> **This notebook will serve as an EDA report for this dataset. Your task is to examine results from each step and add a summary at the end of the notebook that addresses the given questions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFaENwcMUGMd"
   },
   "source": [
    "# About the dataset\n",
    "\n",
    "The dataset is available on [Kaggle](https://https://www.kaggle.com/), a popular platform for data science competitions and projects.\n",
    "\n",
    "The dataset contains various attributes or features associated with individuals, particularly from India, who have been diagnosed as either diabetic or non-diabetic. Each row typically represents one individual, and each column represents a specific attribute or feature.\n",
    "\n",
    "The original objective of the dataset is to diagnostically **predict whether or not a patient has diabetes, based on certain diagnostic measurements** included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eL4eGZVYV0Io"
   },
   "source": [
    "# EDA checklist\n",
    "\n",
    "The first step in any data analysis task is to create different summaries of the data that help understand the dataset properties. As a result of a comprehensive Exploratory Data Analysis you should have as a result a cleaned and filtered dataset, where any errors in the data, format conversions and value scale adjustments have been addressed.\n",
    "\n",
    "\n",
    "Ok. Let's start!\n",
    "This the plan\n",
    "1. Load python packages\n",
    "2. Load dataset by using Pandas\n",
    "3. Check the data content and dimensions\n",
    "4. Then take a closer look on statistical summary of data to identify missing values\n",
    "5. Devise a data cleaning and preprocessing strategy\n",
    "6. Exploring relationships between features (correlations)\n",
    "7. Identify patterns and outliers, revise data cleaning and preprocessing as relevant\n",
    "8. Summarize findings, decisions based on these and how they were achieved. Describe the resulting analysis-ready dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3k7uCT0GYckP"
   },
   "source": [
    "# 1. Load Python packages\n",
    "\n",
    "Import basic Python datascience packages/libraries.\n",
    "This tutorial assumes Python version 3.6+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0c0u1JXHOJz-"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYkkDmk3bW77"
   },
   "source": [
    "# 2. Load dataset by using Pandas\n",
    "\n",
    "Option 1: run the code from google colab, load the data from CBM101 git repository as following\n",
    "\n",
    "Option 2: If you run the notebook in your machine locally, you can load the dataset by giving local path for the dataset.\n",
    "\n",
    "```\n",
    "df = pd.read_csv('/your path to directory/diabetes.csv')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EpkHfByIe5rS"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/thilinib/CBM101/main/assets/diabetes.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_45d5A5xayPN"
   },
   "source": [
    "Now the pandas .csv file is transformed to a python data structure DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeSK2fWHgx25"
   },
   "source": [
    "# 3. Check the data content and dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qm8clvaqQCzo",
    "outputId": "501ccd61-6dc1-466b-b6d6-37952bd4c25c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dj0eiWEvftKA",
    "outputId": "ba3ad749-bde4-402a-be2d-ba0017efec2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how dataset looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ea-WmC3lWYo"
   },
   "source": [
    "Another important method is *info()* which gives a quick description of the data, in particular the total number of rows, and each attribute’s type and number of non-null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PvmwVr8fvGl",
    "outputId": "3489971b-e8d4-445f-befd-71a88f36be99"
   },
   "outputs": [],
   "source": [
    "# check the data types and general info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nSiw8LQmUPa"
   },
   "source": [
    "\n",
    "\n",
    "> **Make a note to your EDA report summary**: Do you notice that there is need to do any data type conversions e.g. encoding group categories as numbers? (hint: Are all columns containing numeric data? )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa2u0HYgm58U"
   },
   "source": [
    "The code below is demonstrating an example of how to perform type conversion - for this feature it is actually not needed so after demonstrating how this is done, we will actually revert the type back to what it was originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owuiXBPrfxBY"
   },
   "outputs": [],
   "source": [
    "#change Glucose Dtype\n",
    "df.Glucose = df.Glucose.astype(object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_y3XggOfyk4",
    "outputId": "1b64ca87-51a3-4447-cff3-f0073315f681"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEzpQG2UB2I0"
   },
   "source": [
    "In info table check the 'Dtype'. For machine learning downstream tasks we are expecting to see int or float. You can notice that Glucose is now of \"object\" type. So let's revert it back to numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtjoEZ0Fh1L5",
    "outputId": "5fbd8d53-4e83-4e12-a2bc-9e5f4f84ab96"
   },
   "outputs": [],
   "source": [
    "df.Glucose = df.Glucose.astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Hym237IiFyG"
   },
   "source": [
    "# 4. Statistical summary of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "8PSUDNGPB3n2",
    "outputId": "3aca5651-f61c-42d5-8905-7f3bc90c7977"
   },
   "outputs": [],
   "source": [
    "# check the summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZaGU692B18n"
   },
   "source": [
    "In descriptive statistic we can see,\n",
    "\n",
    "\n",
    "*   **Count**: The count column indicates the number of non-null values for each variable. If these values vary by column, this can suggest that there are missing values.\n",
    "*   **Mean (Average)**: The mean represents the average value of each variable across all observations. For example, the mean number of pregnancies is approximately 3.85, the mean glucose level is around 120.89 mg/dL, and so forth.\n",
    "\n",
    "*   **min :** Examine whether there are an unusually small values. E.g. consider based on your biological knowledge that data for glucose level, blood pressure, skin thickness, insulin level and BMI.\n",
    "*   **max: ** Examine whether there are an unusually large values.\n",
    "\n",
    "\n",
    "*   **Standard Deviation (Std):** The standard deviation measures the dispersion or variability of values around the mean. A higher standard deviation indicates greater variability in the data. For instance, variables like insulin and blood pressure have relatively high standard deviations compared to others, suggesting wider variability in their values which could be biological or indicate some technical issues with these measurements\n",
    "\n",
    "*   **Percentiles (25th, 50th, 75th):** These percentiles provide insights into the distribution and spread of the data. If the mean and median(50th) are close to each other, it suggests that the data is approximately symmetrically distributed and likely has low skewness. However, if the mean is significantly larger or smaller than the median, it indicates skewness in the data like Insulin.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "It is always good to check the above info feature by feature. In addition, you should also compare the features: Do we have features that can dominate others in magnitude?\n",
    "If yes, you should consider if data needs to be scaled?\n",
    "\n",
    "\n",
    "\n",
    "> **Make a note to your EDA summary**: Did you notive unusual/suspicious values? If yes, describe your observations. Comment also on the need to scale feature values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy8gtew0lFDk"
   },
   "source": [
    "# 5. Data cleaning and preprocessing\n",
    "\n",
    "Most Machine Learning algorithms cannot work with missing values. The goal in this section is to learn how to detect and remove those observations (in this case data for a given individual) that include missing values, or alternatively impute (i.e. replace with some value) missing values.\n",
    "\n",
    "In the code below we inspect two scenarios: i) value is missing in the original table and assigned \"null\" when read into Python, ii) zero value is used to indicate that no information was available. Additionally, it could also be worth checking for \"na\", \"NA\", or other ways that this could be encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7j0osgzjmCzp",
    "outputId": "8f671c91-8bda-419c-9697-1ae787b36c13"
   },
   "outputs": [],
   "source": [
    "#check null values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCJACWFomYTJ",
    "outputId": "d422df3f-e3b8-4a94-c6c1-3403b5b717b9"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caA34R3cCCfk",
    "outputId": "8ce3a5cd-1ff1-4177-815a-ed59b76f31ec"
   },
   "outputs": [],
   "source": [
    "# missing values (zero values)\n",
    "(df == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NOHhwWBCH6l",
    "outputId": "a4a2165b-3efa-4116-8c32-c50cd61a5d1a"
   },
   "outputs": [],
   "source": [
    "# missing values (zero values) percentage\n",
    "(df == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u42J-5CGmvyH"
   },
   "source": [
    "We can see that there are some features with zero values. However, we should first distinsguish which are real zeros from likely missing values, and then think how we can solve this issue.\n",
    "\n",
    "> **Make a note to your EDA summary** Specify for each feature whether zero values are meaningful. E.g. consider variables like \"Pregnancies\" vs features such as \"Glucose\" or \"BloodPressure\". Summarize how much missing values are present to guide the choice between imputation or removal.\n",
    "\n",
    "This choice depends on various factors including the distribution of the data and the specific objectives of the analysis.\n",
    "\n",
    "We will show one strategy to solve this issue step by step below. First lets identify observations with many missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7HIZ4D_TCqVc",
    "outputId": "28fa9712-53fb-42c3-9fe0-68a9a8cff269"
   },
   "outputs": [],
   "source": [
    "# check the shape after dropping the rows with zero values in three features\n",
    "df[(df.BloodPressure != 0) & (df.SkinThickness != 0) & (df.Insulin != 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7U8IPBTCsRD",
    "outputId": "45077578-43c6-4ab1-f32a-8c1862d29674"
   },
   "outputs": [],
   "source": [
    "# calculate the percentage of the data if dropping the rows with zero values in these features\n",
    "df[(df.BloodPressure != 0) & (df.SkinThickness != 0) & (df.Insulin != 0)].shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIt_YQbisCMo"
   },
   "source": [
    "> **Make a note to your EDA summary** What proportion of data is lost if data entries with suspected missing values are removed? You can report for the above selection and try also different alternative ways, based on what features you consider may have missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoJlTSbNC3FZ"
   },
   "source": [
    "We can check duplicates and scatter matrix to help in deciding what to do with zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Topa3bE2C6Ac",
    "outputId": "7c9726ee-8e35-4bdd-c7c0-26839d103046"
   },
   "outputs": [],
   "source": [
    "# check duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bo5qTzVUC8Pr",
    "outputId": "cf33d3c8-940c-4ab8-cd7e-89f29c296090"
   },
   "outputs": [],
   "source": [
    "# check scatter matrix\n",
    "pd.plotting.scatter_matrix(df, figsize=(15,15), range_padding=0.3, alpha=0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0Gc55-gC-s3"
   },
   "source": [
    "On scatterplots you can spot \"saturation\" of zeros if many data points separate out from the \"data cloud\" at zero value. If there are several such observations, one strategy is to remove these observations, especially those with a lot of zeros. Below we remove observations if value for SkinThickness and Insulin is zero.\n",
    "\n",
    "> **Make a note to your EDA summary** What did you observe in the scatter plots? Comment also on your choice of what data to remove in case you adapt the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQPRbGK1DBIU"
   },
   "outputs": [],
   "source": [
    "# let's drop the rows with zero values\n",
    "df = df[(df.SkinThickness != 0) & (df.Insulin != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pH444i6RDDTj",
    "outputId": "44df7994-3924-420e-ebfe-3f1730331a66"
   },
   "outputs": [],
   "source": [
    "# check the amount of missing values (zero values) after dropping the rows\n",
    "(df == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddf5EZTwDLEp",
    "outputId": "7333b67d-c1fa-4db0-cc43-ad1b086c1367"
   },
   "outputs": [],
   "source": [
    "# check the percentage of missing values (zero values) after dropping the rows\n",
    "(df == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzv2HnJqDN-a"
   },
   "source": [
    "> **Make a note to your EDA summary**: Does it looks like we have removed most of them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHYDMzh22Fy1"
   },
   "source": [
    "You can use the dataset as now or if you wish you can remove remaining zero values in other features.\n",
    "\n",
    "If removal of these observations leads to considerable loss of datapoints, as alternative, we can do imputation. There are lot of ways to impute data. Below, we provide code that simply imputes the missing values by each feature mean. This is the default in the Pycaret package (but only works if missing values are null and not encoded by zero).\n",
    "\n",
    "Following is an example for Glucose zero value imputation (notice that this is applied to dataset that already went through the removal step based on skinThickness and Insulin):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdvBXIu7qc3c",
    "outputId": "021bc3a0-10dd-4f63-842b-e21d370fbcb3"
   },
   "outputs": [],
   "source": [
    "# Calculate the mean of 'Glucose' excluding zero values\n",
    "glucose_mean = df[df['Glucose'] != 0]['Glucose'].mean()\n",
    "\n",
    "# Impute missing values (zero values) in 'Glucose' with the calculated mean\n",
    "df['Glucose'] = df['Glucose'].replace(0, glucose_mean)\n",
    "\n",
    "# Display the DataFrame with imputed values\n",
    "print(df['Glucose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "doA4uGXxsI2a",
    "outputId": "1b0edcbb-e5b2-424d-c638-13ceca4d565d"
   },
   "outputs": [],
   "source": [
    "# missing values (zero values) percentage\n",
    "(df == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVQZmvKUsKrk"
   },
   "source": [
    "\n",
    "You can see there's no any 0 values for Glucose.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBZ6HPI-v-4-"
   },
   "source": [
    "Now let's visualize features seperately.\n",
    "\n",
    "Visualizations are often used to intuitively understand the distribution of the data.\n",
    "\n",
    "Histograms can be used to visualize the distribution of continuous data/features. A histogram shows the number of instances (on the vertical axis) that have a given value range (on the horizontal axis).\n",
    "\n",
    "> **Make a note to your EDA summary**: Do you observe unusually low/high values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AgiKypwCCQ-j",
    "outputId": "de272ba8-3ee7-4f2e-a079-23736e7a4c1d"
   },
   "outputs": [],
   "source": [
    "#Plot all values on a frequency graph (showing how often they occur).\n",
    "df.hist(bins=50, figsize=(10,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYVOZWM8xZhA"
   },
   "source": [
    "If a feature looks suspicious, you can sort values and show how many such values are in the data using the following code (exemplified by glucose level and blood pressure )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6tyFth7CY7x",
    "outputId": "74a5a87a-9480-4ea4-8513-6fd3959c3d57"
   },
   "outputs": [],
   "source": [
    "# lower limit of the diastolic blood pressure\n",
    "df.BloodPressure.value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gKArVfwCe-c"
   },
   "source": [
    "> **Make a note to your EDA summary**: Are there several unusual values? If yes, you should consider how to handle them. Examine and include comment to your summary from all of the features that looked suspicious based on the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_nRz4WoCd-Y",
    "outputId": "ba302525-a971-44a7-ae1b-fa4bf8ff7a19"
   },
   "outputs": [],
   "source": [
    "# lower limit of the skin thickness\n",
    "df.SkinThickness.value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wgHd4NKCobO",
    "outputId": "7e6adcc4-e6f7-4990-e0d3-5f74af72b091"
   },
   "outputs": [],
   "source": [
    "# lower limit of the glucose\n",
    "df.Glucose.value_counts().sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRk0EMoP4Fst"
   },
   "source": [
    "\n",
    "\n",
    "You can also re-plot the scatter matrix after cleaning data (i.e. in code above the removal of observations with  missing values in two specific features).\n",
    "\n",
    "> **Make a note to your EDA summary**: Compare to the plots before/after data cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "li865OZWDNZg",
    "outputId": "01c1e0f6-7120-4c1e-d1d0-4d92507132f1"
   },
   "outputs": [],
   "source": [
    "# check scatter matrix after dropping the rows with zero values\n",
    "pd.plotting.scatter_matrix(df, figsize=(15,15), range_padding=0.3, alpha=0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-VhM6ZL4431"
   },
   "source": [
    "# 6. Exploring relationships between features(correlations)\n",
    "\n",
    "Since the dataset is not too large, we can easily compute the standard correlation coefficient (also called Pearson’s r) between every pair of attributes using the *corr()* method:\n",
    "\n",
    "Calculating correlation on very large datasets can be  computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PshC1Yln5rBJ"
   },
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nO4z5C2j563F"
   },
   "source": [
    "Now let’s look first at how much each attribute correlates with the outcome feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SfzZwyGR5vr-",
    "outputId": "73d9a2a8-6a66-4161-81ee-bbd640683121"
   },
   "outputs": [],
   "source": [
    "corr_matrix[\"Outcome\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwBa0Qi36Sbf"
   },
   "source": [
    "We can see all have positive correlations with the outcome variable. Next, we can visualize the correlation values for each other simply using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "id": "7012IvG3DYpM",
    "outputId": "2286e436-0628-4c97-eafb-007e41645375"
   },
   "outputs": [],
   "source": [
    "# check the correlation matrix\n",
    "sns.heatmap(df.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YoZ3932d6ywg"
   },
   "source": [
    "\n",
    "\n",
    "Using the correlation matrix, we get a complete picture of the correlations amongst the variables and their effect on the outcome.\n",
    "\n",
    "Here, we can see that the feature ‘glucose’ has a high correlation with the outcome, which is expected.\n",
    "\n",
    "> **Make a note to your EDA summary:** Do the features have strong correlation to each other? If yes, you should consider dropping redundant features (e.g. columns \"height in cm\" and \"height in inches\" would be redundant).\n",
    "\n",
    "Another way to check for correlation between attributes is to use Pandas’ scatter_matrix function, (we already drew it)which plots every numerical attribute against every other numerical attribute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGr6dVzr5QZ0"
   },
   "source": [
    "# 7. Identify patterns and outliers\n",
    "\n",
    "In order to check existing patterns in dataset, we can use visualization plots like scatter, histogram etc.\n",
    "\n",
    "Let's see how we can plot value distribution of each feature for diabetics vs non-diabetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WAmX-CfcCQVH",
    "outputId": "5b680bfd-5d5f-4e03-ef9c-8322f8a2f725"
   },
   "outputs": [],
   "source": [
    "bins = 12\n",
    "plt.figure(figsize=(15,18))\n",
    "\n",
    "for i, feature in enumerate(df.columns):\n",
    "    rows = int(len(df.columns)/2)\n",
    "    plt.subplot(rows, 3, i+1)\n",
    "    sns.histplot(df, x = feature, hue='Outcome', common_norm = False, stat='density')\n",
    "    sns.kdeplot(x = df[feature], hue=df['Outcome'], common_norm = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpzEXmXtElrV"
   },
   "source": [
    "From the statistical summary you have seen the Insulin has a high standard deviation and quartile values. This can also be visually observed here. Should we consider the very high values as outliers for Insulin?\n",
    "\n",
    "For more insight, lets plot box plots. These can be used as a quick check of the value distributions of each feature and they indicate the interquartile range and candidate outliers.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "f_9AD8TrClzP",
    "outputId": "3e36e598-6db2-4f7f-ef35-0befaea21b22"
   },
   "outputs": [],
   "source": [
    "df.boxplot(figsize=(15, 10))\n",
    "plt.title('Box Plot for All Features')\n",
    "plt.ylabel('Values')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl1x6GtvJMuL"
   },
   "source": [
    "If there are many clear outliers in the features, an additional data cleaning strategy may be needed, in addition to the approach to handling zero values that we added to the analysis code earlier. This strategy could involve imputing outliers e.g. with the median of each respective feature. The benefit of an imputing strategy is that it allows for the retention of all data points while addressing the outliers. Can you think of any caveats?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0BDikUL1nA7"
   },
   "source": [
    "After completing the preprocessing steps, it's a good practice to save the preprocessed dataset for future use in machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gTT3Buj0r-1"
   },
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_diabetes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEahQTgDiZAe"
   },
   "source": [
    "\n",
    "# Exercise\n",
    "**Summarize each step of the analysis, focusing on what was observed, what was decided based on it, and how it was accomplished.** Refer to the plan at the beginning and \"Make a note\" parts highlighted in the notebook to ensure you address all key points.\n",
    "\n",
    "\n",
    "\n",
    "*   Statistical summary of data\n",
    "*   Detecting missing values and outliers\n",
    "*   Feature correlations\n",
    "\n",
    "\n",
    "Describe the analysis-ready processed dataset (how many observations it contains, were all features kept for downstream analysis).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
